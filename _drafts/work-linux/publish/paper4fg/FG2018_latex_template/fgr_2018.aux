\relax 
\citation{wagner2012toward}
\citation{roth2015unconstrained}
\citation{roth2016adaptive}
\citation{jourabloo2015attribute}
\citation{guo2016dynamic}
\citation{hu2014robust}
\citation{vogler2007best}
\citation{ren2014face}
\citation{tecootes1994active}
\citation{edwards1998interpreting}
\citation{matthews2004active}
\citation{valstar2010facial}
\citation{dollar2010cascaded}
\citation{cao2014face}
\citation{xiong2013supervised}
\citation{tzimiropoulos2015project}
\citation{ren2014face}
\citation{kazemi2014one}
\citation{cao2014face}
\citation{burgos2013robust}
\citation{sagonas2013300}
\citation{shen2015first}
\citation{peng2016sequential}
\citation{decarlo2000optical}
\citation{vogler2007best}
\citation{wettum2017facial}
\citation{sanchez2016cascaded}
\citation{sanchez2016cascaded}
\citation{peng2016sequential}
\citation{sung2009adaptive}
\citation{asthana2014incremental}
\citation{peng2015piefa}
\@writefile{toc}{\contentsline {section}{\numberline {I}INTRODUCTION}{1}}
\citation{sanchez2016cascaded}
\citation{wright2009robust}
\citation{perakis20133d}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Summary of the existed approaches for real-time face alignment. The red points represent the face shapes of current frames, the black point represents the mean face shape. The blue region, in which the face shapes of last frames may occur, indicates the ability that offline FDMs express the corresponding shape residuals. (a) represents the static face alignment based approaches. (b) represents the tracking based approaches, and the offline FDMs of these approaches can only tackle a part of the whole search region, in which the face shapes of last frames may occur. (c) represents the incremental learning based approaches and our proposed strategy, they all can enlarge offline FDM's in (b) expression to shape residuals. What the difference is, our strategy achieves that by an offline training task. \relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:niubility}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {I-A}Compressive sensing based approach for real-time face alignment}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Method}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-A}Compressive Sensing and Sparse Representation}{2}}
\citation{breiman2001random}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-B}Compressive Sensing Based Offline FDM (CS-OFDM)}{3}}
\newlabel{e:CS0}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-C}Training of Compressive Sensing Based Offline FDM}{3}}
\newlabel{e:CS1}{{3}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {II-C.1}Sequential training samples simulation}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {II-C.2}Training CS-OFDM}{3}}
\newlabel{e:barwq8}{{4}{3}}
\citation{kazemi2014one}
\citation{cao2014face}
\citation{kazemi2014one}
\citation{le2012interactive}
\citation{belhumeur2013localizing}
\citation{sagonas2013semi}
\citation{shen2015first}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  Sparse coding. The regression tree based sparse transform encodes the shape residual into a sparse representation. \relax }}{4}}
\newlabel{fig:sparse_representation}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Real-time face alignment utilizing the trained CS-OFDM. CS-OFDM uses last face shape $\mathaccentV {hat}05E{X}_{t-1}$ to estimate the shape residual $\Delta X_t$ between $\mathaccentV {hat}05E{X}_{t-1}$ and the current face shape $\mathaccentV {hat}05E{X}_t$ to be fitted. Then $(\mathaccentV {hat}05E{X}_{t-1} +\mathaccentV {hat}05E{X}_{t-1})$ is obtained to fit $\mathaccentV {hat}05E{X}_t$. if the fitting result is accepted by the reboot scheme, the real-time face alignment is going on. Otherwise, reboot is performed from the mean shape $\mathaccentV {bar}016{X}$. \relax }}{4}}
\newlabel{fig:fitting}{{3}{4}}
\newlabel{e:barwq8}{{5}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-D}Fitting Facial Shape Utilizing Trained CS-OFDM}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Experiments}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}Implementation Details}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Datasets}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Cumulative error curve of the proposed method (red) and the Chehra tracker (black) on 300-VW dataset (49 landmarks). The overview of delivery system. \relax }}{5}}
\newlabel{fig:nmse1}{{4}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  The frame-by-frame average RMSE plot for proposed method (red) and the Chehra tracker (black) on 300-VW dataset(49 landmarks). \relax }}{5}}
\newlabel{fig:nmse2}{{5}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Cumulative error curve of the proposed method (red) and the Chehra tracker (black) on image scale changed 300-VW dataset (49 landmarks). The overview of delivery system. \relax }}{6}}
\newlabel{fig:nmse3}{{6}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  The frame-by-frame average RMSE plot for proposed method (red) and the Chehra tracker (black) on image scale changed 300-VW dataset(49 landmarks). \relax }}{6}}
\newlabel{fig:nmse4}{{7}{6}}
\bibstyle{ieeetr}
\bibdata{conference.bib}
\bibcite{wagner2012toward}{1}
\bibcite{roth2015unconstrained}{2}
\bibcite{roth2016adaptive}{3}
\bibcite{jourabloo2015attribute}{4}
\bibcite{guo2016dynamic}{5}
\bibcite{hu2014robust}{6}
\bibcite{vogler2007best}{7}
\bibcite{ren2014face}{8}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-C}Comparision}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {III-C.1}Evaluation on 3 scenarios}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {III-C.2}Robust evaluation}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {III-C.3}Analysis of real-time performance}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusion}{7}}
\@writefile{toc}{\contentsline {section}{References}{7}}
\bibcite{tecootes1994active}{9}
\bibcite{edwards1998interpreting}{10}
\bibcite{matthews2004active}{11}
\bibcite{valstar2010facial}{12}
\bibcite{dollar2010cascaded}{13}
\bibcite{cao2014face}{14}
\bibcite{xiong2013supervised}{15}
\bibcite{tzimiropoulos2015project}{16}
\bibcite{kazemi2014one}{17}
\bibcite{burgos2013robust}{18}
\bibcite{sagonas2013300}{19}
\bibcite{shen2015first}{20}
\bibcite{peng2016sequential}{21}
\bibcite{decarlo2000optical}{22}
\bibcite{wettum2017facial}{23}
\bibcite{sanchez2016cascaded}{24}
\bibcite{sung2009adaptive}{25}
\bibcite{asthana2014incremental}{26}
\bibcite{peng2015piefa}{27}
\bibcite{wright2009robust}{28}
\bibcite{perakis20133d}{29}
\bibcite{breiman2001random}{30}
\bibcite{le2012interactive}{31}
\bibcite{belhumeur2013localizing}{32}
\bibcite{sagonas2013semi}{33}
