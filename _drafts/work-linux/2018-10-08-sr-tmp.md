---
layout: post
title: "SR-paper-notes(未完成)"
date: 2018-10-08
description: "SR papers"
tag: Research
---

### 目录

* [Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network---ESPCN](#ESPCN)

### <a name= "ESPCN"></a>Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network

#### __Introduction__

|     Categories                               | Description                               |
| ------------                                 | ------------------------------            |
| _Multi-image SR method_                                 |     _利用多帧图像进行SR_                |
| __Redundancy-constrained method__                                | __利用冗余对原ill-posed问题进行约束, 试图直接解决下采样带来的oen-to-many问题__          |

这两类方法的缺陷:

+ 需要复杂的图像配准、融合计算, 这些步骤一旦不好将直接影响最终的重建结果

单图像超分技术(Single Image Super-resolution------SISR): 利用单一LR图来进行HR图重建, 这类技术通常利用空间域局部图像相关性或者时域相关性以达到隐式利用redundancy的目的, 这也就意味着需要prioir来限制解空间.

|     Categories                               | Representative work                               |
| ------------                                 | ------------------------------            |
| _Edge-based method_                                 |     _[35]_                |
| __Image statistics-based method__                   | __[9, 18, 46, 12]__          |
| _Patch-based method_                                 |     _[2, 43, 52, 13, 54, 40, 5]_                |
| __Sparse-based method__                   | __认为图像在某些变换域里具有稀疏表示, 这里通常用字典学习获得稀疏变换, 也就是双字典方法.[47, 8]__          |
| _neural network-based method_                                 |     _[6, 4, 27, 7, 3, 44]_                |

Sparse-based method的缺陷: 引入稀疏约束后, 往往需要非线性优化求解, 这会增加计算量.

neural network-based method:

[6, 4, 27](C. Dong, C. C. Loy, K. He, and X. Tang. Learning a deep convolutional network for image super-resolution, Z. Cui, H. Chang, S. Shan, B. Zhong, and X. Chen. Deep network cascade for image super-resolution, C. Osendorfer, H. Soyer, and P. van der Smagt. Image superresolution with fast approximate convolutional sparse coding.)稍微有点老, 是14年的文章.

[7](C. Dong, C. C. Loy, K. He, and X. Tang. Image super-resolution using deep convolutional networks.)是2015年TPAMI的文章, 这篇文章是受稀疏编码方法的启发而提出的多层卷积神经网络方法.

[3](Y. Chen and T. Pock. Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration.)也是2015年的一篇文章, 这篇文章提出使用multi-stage trainable nonlinear nonlinear reaction diffusion(TNRD)来替换CNN.

[44](Z. Wang, D. Liu, J. Yang, W. Han, and T. Huang. Deeply improved sparse coding for image super-resolution.)也是2015年的文章, 受10年的稀疏编码方法LISTA(K. Gregor and Y. LeCun. Learning fast approximations of sparse coding.)的启发训练了一个端对端的cascaded 稀疏编码网络, 这个方法的网络结构不局限于神经网络, [比如15年的基于随即森林的SISR方法](S. Schulter, C. L istner, and H. Bischof. Fast and accurate image upscaling with super-resolution forests.)

[27]方法中, 图像的分辨率中网络的中间层开始逐渐增加; 而[7, 44, 3]是在网络第一层之前或者在第一层开始增加, 然而伴随着这三个方法就产生了如下缺陷:1)增加了计算量, 尤其是对CNN-based方法
这种处理速度直接受输入图像分辨率影响的尤其明显;2)这三个方法用到了差值方法, 但是没有引入附加信息来解决ill-posed问题.

[6]这个方法利用CNN来学习上采样因子.

本文方法在网络的末端利用LR特征进行HR数据恢复、提高分辨率, 为了达到这个目的, 学习了一层亚像素卷积层来学习上采样因子, 进而实现了图像、视频超分. 本文方法具体的优势体现在:

+ 网络的最后一层是upscaling, 其他层在LR输入上进行特征提取, 由于LR图像的尺寸比较小, 这也就意味着我们可以采用更小的滤波器, 从而获得更快的计算速度
+ upscaling fiter的个数是$n_L - 1$, 对应着$n_L - 1$个feature map, 另外本文没有显示的利用差值, 这也就意味着让网络去隐式的去学习这种能力(个人理解: 显示差值一般都是pre-defined, 泛化能力没那么好)

实验材料:

+ 公开的一些benchmark数据集: xxx
+ 对比方法: LISTA(upscaling的非deep learning方法), [7], [3]

#### __Method__

__总结:__ LR空间做特征工程(计算量小), 亚元素层做upscale.

[7]先对LR图像进行上采样、插值, 然后再利用神经网络结构进行特征工程、恢复HR图像, 可见这篇文章采用的是通用思路: 把重建当成一个de-aliasing问题. 与之不同的是, 本文的神经网络结构直接
作用于LR图像进行特征工程, 然后再进行upscaling. 网络中各层主要分工情况为: 前面的层进行LR图像特征提取, 最后一层的亚元素层进行upscaling.

##### 特征工程:

网络的前$L-1$层就是做特征工程的卷积层, 我没觉得有什么特别的, 而且总觉得网络结构的图例描述与正文描述有冲突, 图例描述说有两层网络, 而正文中是$L-1$层.

##### upscaling:

Deconvolution layer: 从max-pooling和其他图像dow-sampling的结果恢复分辨率, 该层的一个成功应用就是14年的[49](Visualizing and understanding convolutional networks)和14年的[24](Fully convolutional networks for semantic segmentation.)利用网络的高阶特征生成语义分割. 此外, SRCNN中使用的双三次插值是deconvolution layer的一个special case[24, 7]; Deconvolution layer会按照步长$r$将input pixel与filter相乘、相加, 然而, 任何卷积后的reduction/summing都是expensive.

其他upscale LR图像的方法: [24]的$/frac{1}{r}$分数步长卷积; [27]的perforate以及[49]提到的LR图像到HR图像的un-pooling, 然后在HR图像上执行步长为1的卷积操作.

上面提到的分数卷积: 如果在LR图像上执行步长为$/frac{1}{r}$的分数卷积操作, 且大小为$k_s$滤波$W_s$的weight spacing为$/frac{1}{r}$, 这将导致滤波$W_s$的部分参与卷积计算, 部分不参与计算. 其中, activation pattern的个数是$r^2$, 对于每个activation pattern, 根据位置的不同, 至多有$\left \lceil \frac{k_s}{r} \right \rceil$个weight被激活, 而且这些pattern是在卷积的
过程中根据亚元素的位置$mod(x, r), mod(y, r)$而周期的被激活的, 其中$x, y$是HR图像的位置.

Sub-pixel convolution layer: 主要是公式3, 4, 实际作用就是upscale, 但这部分的理论没弄清楚. 想理解清楚这部分内容的前提是搞清楚3上面的那两段中涉及的理论. 查阅资料后最终要理解好这句话: we propose an __effective way__ to implement the above __operation__ when $mod(k_s, r) = 0$.

##### loss function

选pixel-wise mean squared error(MSE)

#### __Experiments__

实验结构:

```
├── Experiments
│   ├── Datasets
│   ├── Implementation details
│   ├── Image super-resolution results(3.3)
│   │   ├── Benefits of the sub-pixel convolution layer
│   │   ├── Comparison to the state-of-the-art
│   ├── Video super-resolution results(3.4)
│   ├── Run time evaluations(3.5)

```
##### (3.3)

>* 使用tanh代替relu
>* cost function的改善小于阈值$\mu$停止训练
>* 从Fig4的a、c对比来看EPCN的特征要比SRCNN的更加平滑, 纹理也更加丰富(详细可看原文3.3.1中第二段的描述).

State-of-the-art: SRCNN[7], TNRD[3]

>* 对于SRCNN, 最好的模型是9-5-5ImageNet model
>* 对于TNRD, 则是7x75stages model

表2则是跟如上两个模型做对比, 从结果来看ESPCN和TNRD查不多, 但这两个方法都好于SRCNN. 值得注意的是TNRD的upscale比较简单, 只是利用了双三次插值(may benefit from a trainable nonlinearity function). 这里后面看一下TNRD的nonlinearity function, 并且ESPCN认为他的网络模型与之不排斥.

##### (3.5)

Set14数据集上的runtime实验(upscale 是3):

<div align="center">
	<img src="/images/posts/espcn/runtime.png" height="500" width="500">
</div>

$$ 图1. runtime(引自原文) $$

这是CPU(单核2.0GHz)结果, 从结果来看ESPCN确实比其他方法快, 接近300ms; 对于K2 GPU, ESPCN跑出了4.7ms的速度. 鉴于ESPCN的速度优势, 这篇文章的作者可能会尝试15年的[36](Going deeper with convolutions. In CVPR 2015, 2015)来进一步的提升SR性能.

1080 HD 视频(Xiph, Ultra Video Group数据集)超分runtime实验(upscale 是3):SRCNN 9-5-5 ImageNet model是每帧0.435s, 而ESPCN是每帧0.038s.

1080 HD 视频(Xiph, Ultra Video Group数据集)超分runtime实验(upscale 是4):SRCNN 9-5-5 ImageNet model是每帧0.434s, 而ESPCN是每帧0.029s.

ps: [7], [3], [40](Adjusted anchored neighborhood regression for fast super-resolution.), [31](Fast and accurate image upscaling with super-resolution forests.)提供了Matlab代码.

#### __Conclusion__

>* LR空间做特征提取
>* sub-pixel convolution layer做LR feature 到HR图像的映射

#### __Future work__

>* 视频SR的一个合理假设: 近邻帧共享场景内容, 参考11年的[32](Space-time super-resolution from a single video)和[23](A bayesian approach to adaptive video super resolution)
>* Spatio-temporal networks: 参考13年的[19](3D convolutional neural networks for human action recognition), 15年的[41](Learning spatiotemporal features with 3d convolutional networks)
>* 利用3D卷积将ESPCN拓展成spatio-tempotal network来从多个近邻帧超分恢复一帧图像

### 待办:

position_c

>* 下一篇文章看[7], 即那篇PAMI
>* 复习点扩散函数(point spread function)和高斯滤波
>* cnn基础博客完善包括video和bp
>* 看[49]理解卷积网络和deconvolution layer, 如果有时间的话也可看下[24]关于deconvolution layer或backwards convolution的描述; 这里可能得看下11年的ICCV[50](Adaptive deconvolutional networks for mid and high level feature learning.), 因为是这篇文章提出的deconvolution layer.
>* 看下[24, 7]是如何说明双三次插值是deconvolution layer的一个special case的
>* "Deconvolution layer会按照步长$r$将input pixel与filter相乘、相加, 然而, 任何卷积后的reduction/summing都是expensive.", 目前我对里面的: 具体运算流程, 以及为什么convolution后的summing是expensive这两点理解的不是很深
>* sub-pixel convolution: convolution with fraction stride$/frac{1}{r}$, periodically acticated, sub-pixel postion$mod(x, r), mod(y, r)$, an effective way when $mod(k_s, r)=0$中的effective way具体指的是什么.
>* [review paper](https://eng.ucmerced.edu/people/cyang35/ECCV14/ECCV14.html/)

<br>

转载请注明：[Mengranlin](https://lmrshare.github.io) » [点击阅读原文](https://lmrshare.github.io/2015/09/iOS9_Note/)
