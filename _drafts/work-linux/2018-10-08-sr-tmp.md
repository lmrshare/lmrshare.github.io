---
layout: post
title: "SR-paper-notes(未完成)"
date: 2018-10-08
description: "SR papers"
tag: Research
---

### 目录

* [Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network---ESPCN](#ESPCN)

### <a name= "ESPCN"></a>Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network

#### __Introduction__

|     Categories                               | Description                               |
| ------------                                 | ------------------------------            |
| _Multi-image SR method_                                 |     _利用多帧图像进行SR_                |
| __Redundancy-constrained method__                                | __利用冗余对原ill-posed问题进行约束, 试图直接解决下采样带来的oen-to-many问题__          |

这两类方法的缺陷:

+ 需要复杂的图像配准、融合计算, 这些步骤一旦不好将直接影响最终的重建结果

单图像超分技术(Single Image Super-resolution------SISR): 利用单一LR图来进行HR图重建, 这类技术通常利用空间域局部图像相关性或者时域相关性以达到隐式利用redundancy的目的, 这也就意味着需要prioir来限制解空间.

|     Categories                               | Representative work                               |
| ------------                                 | ------------------------------            |
| _Edge-based method_                                 |     _[35]_                |
| __Image statistics-based method__                   | __[9, 18, 46, 12]__          |
| _Patch-based method_                                 |     _[2, 43, 52, 13, 54, 40, 5]_                |
| __Sparse-based method__                   | __认为图像在某些变换域里具有稀疏表示, 这里通常用字典学习获得稀疏变换, 也就是双字典方法.[47, 8]__          |
| _neural network-based method_                                 |     _[6, 4, 27, 7, 3, 44]_                |

Sparse-based method的缺陷: 引入稀疏约束后, 往往需要非线性优化求解, 这会增加计算量.

neural network-based method:

[6, 4, 27](C. Dong, C. C. Loy, K. He, and X. Tang. Learning a deep convolutional network for image super-resolution, Z. Cui, H. Chang, S. Shan, B. Zhong, and X. Chen. Deep network cascade for image super-resolution, C. Osendorfer, H. Soyer, and P. van der Smagt. Image superresolution with fast approximate convolutional sparse coding.)稍微有点老, 是14年的文章.

[7](C. Dong, C. C. Loy, K. He, and X. Tang. Image super-resolution using deep convolutional networks.)是2015年TPAMI的文章, 这篇文章是受稀疏编码方法的启发而提出的多层卷积神经网络方法.

[3](Y. Chen and T. Pock. Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration.)也是2015年的一篇文章, 这篇文章提出使用multi-stage trainable nonlinear nonlinear reaction diffusion(TNRD)来替换CNN.

[44](Z. Wang, D. Liu, J. Yang, W. Han, and T. Huang. Deeply improved sparse coding for image super-resolution.)也是2015年的文章, 受10年的稀疏编码方法LISTA(K. Gregor and Y. LeCun. Learning fast approximations of sparse coding.)的启发训练了一个端对端的cascaded 稀疏编码网络, 这个方法的网络结构不局限于神经网络, [比如15年的基于随即森林的SISR方法](S. Schulter, C. L istner, and H. Bischof. Fast and accurate image upscaling with super-resolution forests.)

[27]方法中, 图像的分辨率中网络的中间层开始逐渐增加; 而[7, 44, 3]是在网络第一层之前或者在第一层开始增加, 然而伴随着这三个方法就产生了如下缺陷:1)增加了计算量, 尤其是对CNN-based方法
这种处理速度直接受输入图像分辨率影响的尤其明显;2)这三个方法用到了差值方法, 但是没有引入附加信息来解决ill-posed问题.

[6]这个方法利用CNN来学习上采样因子.

本文方法在网络的末端利用LR特征进行HR数据恢复、提高分辨率, 为了达到这个目的, 学习了一层亚像素卷积层来学习上采样因子, 进而实现了图像、视频超分. 本文方法具体的优势体现在:

+ 网络的最后一层是upscaling, 其他层在LR输入上进行特征提取, 由于LR图像的尺寸比较小, 这也就意味着我们可以采用更小的滤波器, 从而获得更快的计算速度
+ upscaling fiter的个数是$n_L - 1$, 对应着$n_L - 1$个feature map, 另外本文没有显示的利用差值, 这也就意味着让网络去隐式的去学习这种能力(个人理解: 显示差值一般都是pre-defined, 泛化能力没那么好)

实验材料:

+ 公开的一些benchmark数据集: xxx
+ 对比方法: LISTA(upscaling的非deep learning方法), [7], [3]

#### __Method__

[7]先对LR图像进行上采样、插值, 然后再利用神经网络结构进行特征工程、恢复HR图像, 可见这篇文章采用的是通用思路: 把重建当成一个de-aliasing问题. 与之不同的是, 本文的神经网络结构直接
作用于LR图像进行特征工程, 然后再进行upscaling. 网络中各层主要分工情况为: 前面的层进行LR图像特征提取, 最后一层的亚元素层进行upscaling.

##### 特征工程:

网络的前$L-1$层就是做特征工程的卷积层, 我没觉得有什么特别的, 而且总觉得网络结构的图例描述与正文描述有冲突, 图例描述说有两层网络, 而正文中是$L-1$层.

##### upscaling:

Deconvolution layer: 从max-pooling和其他图像dow-sampling的结果恢复分辨率, 该层的一个成功应用就是14年的[49](Visualizing and understanding convolutional networks)和14年的[24](Fully convolutional networks for semantic segmentation.)利用网络的高阶特征生成语义分割. 此外, SRCNN中使用的双三次插值是deconvolution layer的一个special case[24, 7]; Deconvolution layer会按照步长$r$将input pixel与filter相乘、相加, 然而, 任何卷积后的reduction/summing都是expensive.

其他upscale LR图像的方法: [24]的$/frac{1}{r}$分数步长卷积; [27]的perforate以及[49]提到的LR图像到HR图像的un-pooling, 然后在HR图像上执行步长为1的卷积操作.

上面提到的分数卷积: 如果在LR图像上执行步长为$/frac{1}{r}$的分数卷积操作, 且大小为$k_s$滤波$W_s$的weight spacing为$/frac{1}{r}$, 这将导致滤波$W_s$的部分参与卷积计算, 部分不参与计算. 其中, activation pattern的个数是$r^2$, 对于每个activation pattern, 根据位置的不同, 至多有$\left \lceil \frac{k_s}{r} \right \rceil$个weight被激活.

Sub-pixel convolution layer:

position_c: Method的2.2. Efficient subpixel convolution layer
### 待办:

>* 下一篇文章看[7], 即那篇PAMI
>* 复习点扩散函数(point spread function)和高斯滤波
>* cnn基础博客完善包括video和bp
>* 看[49]理解卷积网络和deconvolution layer, 如果有时间的话也可看下[24]关于deconvolution layer或backwards convolution的描述; 这里可能得看下11年的ICCV[50](Adaptive deconvolutional networks for mid and high level feature learning.), 因为是这篇文章提出的deconvolution layer.
>* 看下[24, 7]是如何说明双三次插值是deconvolution layer的一个special case的
>* "Deconvolution layer会按照步长$r$将input pixel与filter相乘、相加, 然而, 任何卷积后的reduction/summing都是expensive.", 目前我对里面的: 具体运算流程, 以及为什么convolution后的summing是expensive这两点理解的不是很深

ps: [review paper](https://eng.ucmerced.edu/people/cyang35/ECCV14/ECCV14.html/)

<br>

转载请注明：[Mengranlin](https://lmrshare.github.io) » [点击阅读原文](https://lmrshare.github.io/2015/09/iOS9_Note/)
