---
layout: post
title: <font color="ff0000">Notes about Machine Learning(lhy 35-cnn)[3]</font>
date: 2019-01-06
description: "Research"
tag: Research
---

### 目录

* [CNN](#cnn)
* [Why deep](#why-deep)
* [Semi-supervised Learning](#semi-supervised-learning)

### <a name="cnn"></a>CNN

___Why cnn for image:___

+ 如果用全连接的话, 参数太多
+ cnn的作用是简化神经网络的架构
+ cnn是比dnn更为简单的模型
+ 观察1: 每个神经元只需要连接到图像的一部分
+ 观察2: 同样的pattern可能出现在图像的不同部分, 但是并不需要两个不同的检测器来识别不同位置的pattern(share parameters)
+ 观察3: 图像是具有冗余性的, 因此可以将图像变小来做识别

<div align="center">
	<img src="/images/drafts/lhy-video/whycnn.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whycnn1.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whycnn2.png" height="300" width="600">
</div>

$$图1. why\ cnn(源于lhy视频)$$

___convolution:___

+ 每个filter都是一个矩阵, filter的值是要学习的参数
+ 根据stride来挪动filter, 然后做内积
+ 对于rgb图像, 这个时候filter就是个立方体而不是一个2d的矩阵

<div align="center">
	<img src="/images/drafts/lhy-video/convolution1.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/convolution2.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/convolution3.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/convolution4.png" height="300" width="600">
</div>

$$图2. convolution(源于lhy视频)$$

___convolution and fully connected:___

+ 每个feature map就是hidden layer的输出
+ 每个filter在一个特定位置都看成一个神经元, 同一个filter在不同的位置是share parameter的

<div align="center">
	<img src="/images/drafts/lhy-video/conandfull1.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/conandfull2.png" height="300" width="600">
</div>

$$图3. 和全连接的关系(源于lhy视频)$$

___Max Pooling:___

+ 降维

<div align="center">
	<img src="/images/drafts/lhy-video/maxpooling.png" height="300" width="600">
</div>

$$图4. Max\ pooling(源于lhy视频)$$

___小结:___

<div align="center">
	<img src="/images/drafts/lhy-video/lsummary.png" height="300" width="600">
</div>

$$图5. 小结(源于lhy视频)$$

___Flatten:___

+ 拉直

<div align="center">
	<img src="/images/drafts/lhy-video/flatten.png" height="300" width="600">
</div>

$$图6. flatten(源于lhy视频)$$

___cnn in keras:___

<div align="center">
	<img src="/images/drafts/lhy-video/cnninkerascode.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/cnninkerascode1.png" height="300" width="600">
</div>

$$图7. code(源于lhy视频)$$

___What does CNN learn:___

+ 分析一个filter的结果, 如第k个filter
+ 第k个filter的作用是什么. 现在找一个图像使degree最大(filter的参数固定, 然后找图像使其degree最大), 结果见图8中的2
+ 第三个filter在找斜条纹. 因此每个filter的工作就是找不同角度的pattern
+ fully connected layer在看整张图, 如图8中的3
+ 图样的方法处理输出,  如图8中的4(可见cnn学到的东西和人类的认知是不一样的, 人认为会选出相应的数字图像)
+ 看一下deep dream和deep style, 挺好玩的, 图8中的5有链接
+ 下围棋(图8中的6), 为什么cnn可以下围棋?(搜一下)
+ 下围棋里的cnn没有maxpooling
+ 语音识别
+ 文字处理

<div align="center">
	<img src="/images/drafts/lhy-video/whatdoescnnlearn.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whatdoescnnlearn2.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whatdoescnnlearn3.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whatdoescnnlearn4.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whatdoescnnlearn5.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whatdoescnnlearn6.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whatdoescnnlearn7.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whatdoescnnlearn8.png" height="300" width="600">
</div>

$$图8. What\ does\ cnn\ learn(源于lhy视频)$$

### <a name="why-deep"></a>Why deep

+ 做deep的时候是在做modularization
+ 语音识别应用
+ phoneme: 将其理解成音标. 由于phoneme受到前后phoneme的影响, 为了表示这件事, 提出了Tri-phone
+ 一个phoneme可以拆成几个state
+ step1: 将acoustic feature(描述一个window里的特性)分类, 即: 决定acoustic feature属于哪一个state(传统方法是HMM-GMM)
+ GMM: 用gmm来描述属于某个state的acoustic feature, 但tri-phone的数量太多了. 为了减少参数提出了分布共用.
+ phoneme之间是有关系的, 因此HMM-GMM模型有缺陷的
+ dnn模型
+ Universality theorem: 一层hidden layer就够了. 但这个理论只是描述了可能性, 但是没有交代这种做法多有效率
+ analogy的方式理解为什么用deep

<div align="center">
	<img src="/images/drafts/lhy-video/whydeep1.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whydeep2.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/phoneme.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whydeep3.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whydeep4.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whydeep5.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whydeep6.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whydeep7.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whydeep8.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whydeep9.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/whydeep10.png" height="300" width="600">
</div>

$$图1. Why\ deep(源于lhy视频)$$

+ end-end: 只给输入、输出
+ 端对端出来之后就是把传统方法的中间环节用hidden layer换掉. 极端情况下就是将中间环节全换掉, 结局是跟传统方法打平
+ to learn more

<div align="center">
	<img src="/images/drafts/lhy-video/e2e1.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/e2e2.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/e2e3.png" height="300" width="600">
</div>

$$图2. end\ to\ end(源于lhy视频)$$

### <a name="semi-supervised-learning"></a>Semi-supervised Learning

+ semi-supervised learning: 除了有标签的数据外, 还用到了没标签的数据
+ why: 有标签的数据少, 但没标签的数据很多; 此外, 人也在做semi-supervised learning
+ un-label data会告诉我们一些事

<div align="center">
	<img src="/images/drafts/lhy-video/semi-super1.png" height="300" width="600">
</div>

<div align="center">
	<img src="/images/drafts/lhy-video/semi-super2.png" height="300" width="600">
</div>

$$图1. semi-supervised\ learning(源于lhy视频)$$


<br>

转载请注明：[Mengranlin](https://lmrshare.github.io) » [点击阅读原文](https://lmrshare.github.io/2015/09/iOS9_Note/) 
